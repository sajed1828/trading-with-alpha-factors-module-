{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4f8c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ta\n",
    "from data_resorces import data_source\n",
    "\n",
    "class alpha_factor:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod    \n",
    "    def ta_factor_indcators(df):\n",
    "        df = pd.DataFrame(df, columns=['close', 'high', 'low', 'open', 'volume'])\n",
    "\n",
    "        # RSI\n",
    "        df['rsi'] = ta.momentum.RSIIndicator(df['close']).rsi()\n",
    "\n",
    "        # Stochastic RSI\n",
    "        stoch_rsi = ta.momentum.StochRSIIndicator(df['close'])\n",
    "        df['stoch_rsi'] = stoch_rsi.stochrsi()\n",
    "\n",
    "        # ROC\n",
    "        df['roc'] = ta.momentum.ROCIndicator(df['close']).roc()\n",
    "\n",
    "        # MACD\n",
    "        macd = ta.trend.MACD(df['close'])\n",
    "        df['macd_line'] = macd.macd()\n",
    "        df['macd_signal'] = macd.macd_signal()\n",
    "        df['macd_diff'] = macd.macd_diff()\n",
    "\n",
    "        # Moving Averages\n",
    "        df['sma_20'] = ta.trend.SMAIndicator(df['close'], window=20).sma_indicator()\n",
    "        df['sma_50'] = ta.trend.SMAIndicator(df['close'], window=50).sma_indicator()\n",
    "\n",
    "        # Bollinger Bands\n",
    "        bb = ta.volatility.BollingerBands(df['close'])\n",
    "        df['bb_bbm'] = bb.bollinger_mavg()\n",
    "        df['bb_bbh'] = bb.bollinger_hband()\n",
    "        df['bb_bbl'] = bb.bollinger_lband()\n",
    "        \n",
    "        df[\"returns\"] = df[\"close\"].pct_change()\n",
    "        typical_price = (df[\"high\"] + df[\"low\"] + df[\"close\"]) / 3\n",
    "        df[\"vwap\"] = (typical_price * df[\"volume\"]).cumsum() / df[\"volume\"].cumsum()\n",
    "\n",
    "\n",
    "        return df.dropna()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3262d9bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         timestamp       open       high        low      close    volume  \\\n",
      "15   1749484980000  107749.36  107790.70  107749.36  107790.70   1.66161   \n",
      "16   1749485040000  107790.70  107852.16  107779.97  107840.98   7.11895   \n",
      "22   1749485400000  107867.13  107867.13  107856.33  107860.47   4.04118   \n",
      "27   1749485700000  107880.00  107894.94  107849.47  107894.93   8.45891   \n",
      "30   1749485880000  107856.00  107915.98  107856.00  107897.57   9.32119   \n",
      "..             ...        ...        ...        ...        ...       ...   \n",
      "194  1749495720000  108453.19  108530.00  108446.58  108530.00  16.97442   \n",
      "195  1749495780000  108530.00  108584.80  108488.23  108493.52  22.07898   \n",
      "196  1749495840000  108493.53  108493.53  108477.60  108486.57   4.99809   \n",
      "197  1749495900000  108486.58  108534.80  108486.57  108534.80   7.10149   \n",
      "198  1749495960000  108534.79  108538.50  108497.70  108514.61  10.23251   \n",
      "\n",
      "        close_time quote_asset_volume  number_of_trades  \\\n",
      "15   1749485039999    179081.71128060              1204   \n",
      "16   1749485099999    767557.26127770              2000   \n",
      "22   1749485459999    435893.37087720               801   \n",
      "27   1749485759999    912503.34921040              1500   \n",
      "30   1749485939999   1005733.93580260              2257   \n",
      "..             ...                ...               ...   \n",
      "194  1749495779999   1841337.33069790              1708   \n",
      "195  1749495839999   2396695.33095060              3726   \n",
      "196  1749495899999    542198.55429370              1114   \n",
      "197  1749495959999    770482.89551530              1744   \n",
      "198  1749496019999   1110429.04961050              3016   \n",
      "\n",
      "    taker_buy_base_asset_volume  ... alpha_factors_4 alpha_factors_5  \\\n",
      "15                   1.40622000  ...       -0.777778       -0.017085   \n",
      "16                   3.70376000  ...       -0.888889       -0.036445   \n",
      "22                   1.40081000  ...       -0.888889       -0.058397   \n",
      "27                   4.06464000  ...       -0.666667       -0.067099   \n",
      "30                   3.71576000  ...       -0.777778       -0.055223   \n",
      "..                          ...  ...             ...             ...   \n",
      "194                 12.96417000  ...       -1.000000       -0.661756   \n",
      "195                 13.93948000  ...       -1.000000       -0.832954   \n",
      "196                  3.23534000  ...       -0.888889       -0.724359   \n",
      "197                  5.26573000  ...       -0.888889       -0.793970   \n",
      "198                  3.61466000  ...       -1.000000       -0.866437   \n",
      "\n",
      "     alpha_factors_6  alpha_factors_7  alpha_factors_8  alpha_factors_9  \\\n",
      "15         -0.732827            -1.00        -0.918919           -41.34   \n",
      "16         -0.737884            -1.00        -0.956757            50.28   \n",
      "22         -0.854355            -1.00        -0.854054             6.65   \n",
      "27          0.079142            -1.00        -0.108108           -14.94   \n",
      "30          0.149398            -1.00        -0.691892           -41.57   \n",
      "..               ...              ...              ...              ...   \n",
      "194        -0.861443            -1.00        -0.670270           -76.80   \n",
      "195        -0.867087            -0.85        -0.551351            36.48   \n",
      "196        -0.827684            -1.00        -0.664865             6.95   \n",
      "197        -0.756947            -1.00        -0.864865           -48.23   \n",
      "198        -0.695954            -0.70        -0.778378            20.19   \n",
      "\n",
      "     alpha_factors_10  alpha_factors_11  alpha_factors_12  alpha_factors_13  \n",
      "15           0.828283          0.428468             41.34         -0.276923  \n",
      "16           0.878788          0.498809            -50.28         -0.317949  \n",
      "22           0.580808          0.610225             -6.65         -0.528205  \n",
      "27           0.358586          0.032840             14.94         -0.215385  \n",
      "30           0.166667          0.950430             41.57         -0.235897  \n",
      "..                ...               ...               ...               ...  \n",
      "194          0.055556          0.283901            -76.80         -0.948718  \n",
      "195          0.787879          0.241065             36.48         -0.964103  \n",
      "196          0.585859          0.094478             -6.95         -0.917949  \n",
      "197          0.116162          0.022338            -48.23         -0.892308  \n",
      "198          0.681818          0.016977             20.19         -0.620513  \n",
      "\n",
      "[159 rows x 27 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "\n",
    "# Define helper functions for alpha formulas\n",
    "def rank(series):\n",
    "    return series.rank(pct=True)\n",
    "\n",
    "def ts_rank(series, window):\n",
    "    return series.rolling(int(window)).apply(lambda x: pd.Series(x).rank(pct=True).iloc[-1], raw=False)\n",
    "\n",
    "def delta(series, period=1):\n",
    "    return series.diff(period)\n",
    "\n",
    "def delay(series, period=1):\n",
    "    return series.shift(period)\n",
    "\n",
    "def correlation(x, y, window):\n",
    "    return x.rolling(int(window)).corr(y)\n",
    "\n",
    "def covariance(x, y, window):\n",
    "    return x.rolling(int(window)).cov(y)\n",
    "\n",
    "def signed_power(series, exponent):\n",
    "    return np.sign(series) * (np.abs(series) ** exponent)\n",
    "\n",
    "def stddev(series, window):\n",
    "    return pd.Series(series).rolling(int(window)).std()\n",
    "\n",
    "def sum_(series, window):\n",
    "    return series.rolling(int(window)).sum()\n",
    "\n",
    "def ts_min(series, window):\n",
    "    return pd.Series(series).rolling(int(window)).min()\n",
    "\n",
    "def ts_max(series, window):\n",
    "    return pd.Series(series).rolling(int(window)).max()\n",
    "\n",
    "def decay_linear(series, window):\n",
    "    weights = np.arange(1, int(window) + 1)\n",
    "    return series.rolling(int(window)).apply(lambda x: np.dot(x, weights) / weights.sum(), raw=True)\n",
    "\n",
    "def scale(series):\n",
    "    return series / np.sum(np.abs(series))\n",
    "\n",
    "def product(series):\n",
    "    return pd.Series(series).prod()\n",
    "\n",
    "def sign(series):\n",
    "    return np.sign(series)\n",
    "\n",
    "def log(series):\n",
    "    return np.log(series)\n",
    "\n",
    "def sum_series(series, window):\n",
    "    return series.rolling(int(window)).sum()\n",
    "\n",
    "def Ts_Rank(series, window):\n",
    "    return series.rolling(int(window)).apply(lambda x: pd.Series(x).rank(pct=True).iloc[-1], raw=False)\n",
    "\n",
    "def IndNeutralize(series, group):\n",
    "    return series.groupby(group).transform(lambda x: x - x.mean())\n",
    "\n",
    "def min_(series, window):\n",
    "    return series.rolling(int(window)).min()\n",
    "\n",
    "def ts_argmax(series, window):\n",
    "    return series.rolling(int(window)).apply(np.argmax) / window\n",
    "\n",
    "\n",
    "# Example alpha formula implementation\n",
    "# Alpha Factors\n",
    "class Alpha_Zero:\n",
    " def __init__(self):\n",
    "     super().__init__()\n",
    "\n",
    " @staticmethod       \n",
    " def alpha_1(df):\n",
    "    condition = df['returns'] < 0\n",
    "    expr = np.where(condition, stddev(df['returns'], 20), df['close'])\n",
    "    ranked = rank(ts_max(signed_power(expr, 2), 5))\n",
    "    return ranked - 0.5\n",
    "\n",
    " @staticmethod\n",
    " def alpha_2(df):\n",
    "    log_volume = np.log(df['volume'].replace(0, np.nan))  # Avoid log(0)\n",
    "    delta_log_vol = delta(log_volume, 2)\n",
    "    ranked_delta_log_vol = rank(delta_log_vol)\n",
    "\n",
    "    price_change = (df['close'] - df['open']) / df['open']\n",
    "    ranked_price_change = rank(price_change)\n",
    "\n",
    "    return -1 * correlation(ranked_delta_log_vol, ranked_price_change, 6)\n",
    "\n",
    " @staticmethod\n",
    " def alpha_3(df):\n",
    "    return (-1 * correlation(rank(df['close']), rank(df['volume']), 10))\n",
    "\n",
    " @staticmethod\n",
    " def alpha_4(df):\n",
    "    return (-1 * ts_rank(rank(df['low']), 9))\n",
    "\n",
    " @staticmethod\n",
    " def alpha_5(df):\n",
    "    vwap = df['vwap'].rolling(window=10).mean()\n",
    "    return (rank((df['open'] - vwap)) * (-1 * rank(df['close'] - df['vwap']).abs()))\n",
    "\n",
    " @staticmethod\n",
    " def alpha_6(df):\n",
    "    return (-1 * correlation(df['open'] , df['close'], 10))\n",
    "\n",
    " @staticmethod\n",
    " def alpha_7(df):\n",
    "    adv20 = df['volume'].rolling(window=20).mean()\n",
    "    delat_close_7 = delta(df['close'], 7)\n",
    "    ts_r = ts_rank(abs(delat_close_7), 60)\n",
    "    \n",
    "    return pd.Series( np.where(\n",
    "            adv20 < df['volume'],\n",
    "            (-1 * ts_r * np.sign(delat_close_7)),\n",
    "            -1.0\n",
    "        ),\n",
    "        index=df.index\n",
    "    )\n",
    "\n",
    " @staticmethod\n",
    " def alpha_8(df):\n",
    "    term = df['open'].rolling(5).sum() * df['returns'].rolling(5).sum()\n",
    "    return -1 * rank(term - delay(term, 10))\n",
    "\n",
    " @staticmethod\n",
    " def alpha_9(df):\n",
    "    delta_close = delta(df['close'], 1)\n",
    "    return np.where(\n",
    "        ts_min(delta_close, 5) > 0,\n",
    "        delta_close,\n",
    "        np.where(ts_max(delta_close, 5) < 0, delta_close, -1 * delta_close)\n",
    "    )\n",
    "\n",
    " @staticmethod\n",
    " def alpha_10(df):\n",
    "    delta_close = delta(df['close'], 1)\n",
    "    cond = np.where(\n",
    "        ts_min(delta_close, 4) > 0,\n",
    "        delta_close,\n",
    "        np.where(ts_max(delta_close, 4) < 0, delta_close, -1 * delta_close)\n",
    "    )\n",
    "    return rank(pd.Series(cond, index=df.index))\n",
    "\n",
    " @staticmethod\n",
    " def alpha_11(df):\n",
    "    diff = df['vwap'] - df['close']\n",
    "    return (rank(ts_max(diff, 3)) + rank(ts_min(diff, 3))) * rank(delta(df['volume'], 3))\n",
    "\n",
    " @staticmethod\n",
    " def alpha_12(df):\n",
    "    return sign(delta(df['volume'], 1)) * (-1 * delta(df['close'], 1))\n",
    "\n",
    " @staticmethod\n",
    " def alpha_13(df):\n",
    "    return -1 * rank(covariance(rank(df['close']), rank(df['volume']), 5))\n",
    "\n",
    " @staticmethod\n",
    " def alpha_14(df):\n",
    "    return (-1 * rank(delta(df['returns'], 3))) * correlation(df['open'], df['volume'], 10)\n",
    "\n",
    " @staticmethod\n",
    " def alpha_15(df):\n",
    "    corrs = rank(correlation(rank(df['high']), rank(df['volume']), 3))\n",
    "    return -1 * corrs.rolling(window=3).sum()\n",
    "\n",
    " @staticmethod\n",
    " def alpha_16(df):\n",
    "    return -1 * rank(covariance(rank(df['high']), rank(df['volume']), 5))\n",
    "\n",
    " @staticmethod\n",
    " def alpha_17(df):\n",
    "    return -1 * rank(covariance(rank(df['close']), rank(df['volume']), 5))\n",
    "\n",
    " @staticmethod\n",
    " def alpha_18(df):\n",
    "    close_open = df['close'] - df['open']\n",
    "    term = stddev(abs(close_open), 5) + close_open\n",
    "    return -1 * rank(term + correlation(df['close'], df['open'], 10))\n",
    "\n",
    " @staticmethod\n",
    " def alpha_19(df):\n",
    "    part1 = -1 * np.sign((df['close'] - df['close'].shift(7)) + df['close'].diff(7))\n",
    "    rolling_sum = df['returns'].rolling(window=250).sum()  \n",
    "    ranked = rolling_sum.rank(pct=True)                    \n",
    "    return part1 * (1 + ranked)  \n",
    " \n",
    " @staticmethod\n",
    " def alpha_20(df):\n",
    "    term = (df['close'] - delay(df['close'], 7)) + delta(df['close'], 7)\n",
    "    return -1 * sign(term) * (1 + rank(1 + df['returns'].rolling(250).sum()))\n",
    "\n",
    " @staticmethod\n",
    " def alpha_21(df):\n",
    "    avg_8 = df['close'].rolling(8).mean()\n",
    "    std_8 = stddev(df['close'], 8)\n",
    "    avg_2 = df['close'].rolling(2).mean()\n",
    "    vol_ratio = df['volume'] / df['volume'].rolling(20).mean()\n",
    "    return np.where(\n",
    "        (avg_8 + std_8) < avg_2, -1,\n",
    "        np.where(avg_2 < (avg_8 - std_8), 1,\n",
    "                 np.where((vol_ratio > 1) | (vol_ratio == 1), 1, -1))\n",
    "    )\n",
    "\n",
    " @staticmethod\n",
    " def alpha_22(df):\n",
    "    return -1 * (delta(correlation(df['high'], df['volume'], 5), 5) * rank(stddev(df['close'], 20)))\n",
    "\n",
    " @staticmethod\n",
    " def alpha_23(df):\n",
    "    return np.where(\n",
    "        (df['high'].rolling(20).mean() < df['high']),\n",
    "        -1 * delta(df['high'], 2),\n",
    "        0)\n",
    "\n",
    " @staticmethod\n",
    " def alpha_24(df):\n",
    "    mean_close_100 = df['close'].rolling(100).mean()\n",
    "    delta_mean = delta(mean_close_100, 100)\n",
    "    delay_close = delay(df['close'], 100)\n",
    "    ratio = delta_mean / delay_close\n",
    "    cond = (ratio < 0.05) | (ratio == 0.05)\n",
    "    return np.where(\n",
    "        cond,\n",
    "        -1 * (df['close'] - ts_min(df['close'], 100)),\n",
    "        -1 * delta(df['close'], 3))\n",
    "\n",
    " @staticmethod \n",
    " def alpha_25(df):\n",
    "    adv20 = df['volume'].rolling(window=20).mean()\n",
    "    return rank(((-1 * df['returns']) * adv20 * df['vwap'] * (df['high'] - df['close'])))\n",
    "\n",
    " @staticmethod\n",
    " def alpha_26(df):\n",
    "    corr_series = correlation(rank(df['volume']), rank(df['vwap']), 6)\n",
    "    sum_corr = sum_(corr_series, 2) / 2.0\n",
    "    rank_sum_corr = rank(sum_corr)\n",
    "    return np.where(rank_sum_corr > 0.5, -1, 1)\n",
    "\n",
    " @staticmethod\n",
    " def alpha_27(df):\n",
    "    adv20 = df['volume'].rolling(window=20).mean()\n",
    "    corr_val = correlation(adv20, df['low'], 5)\n",
    "    middle = (df['high'] + df['low']) / 2\n",
    "    return scale(corr_val + middle - df['close'])\n",
    " \n",
    " @staticmethod\n",
    " def alpha_28(df):\n",
    "    return \n",
    " \n",
    " @staticmethod\n",
    " def alpha_29(df):\n",
    "    return -1 * ts_max(correlation(ts_rank(df['volume'], 5), ts_rank(df['high'], 5), 5), 3)\n",
    "\n",
    " @staticmethod\n",
    " def alpha_30(df):\n",
    "    cond = (sign(df['close'] - delay(df['close'], 1)) +\n",
    "            sign(delay(df['close'], 1) - delay(df['close'], 2)) +\n",
    "            sign(delay(df['close'], 2) - delay(df['close'], 3)))\n",
    "    return ((1.0 - rank(cond)) * sum_(df['volume'], 5)) / sum_(df['volume'], 20)\n",
    "\n",
    " @staticmethod\n",
    " def alpha_31(df):\n",
    "    adv20 = df['close'].rolling(window=20).mean()\n",
    "    part1 = rank(rank(rank(decay_linear(-1 * rank(rank(delta(df['close'], 10))), 10))))\n",
    "    part2 = rank(-1 * delta(df['close'], 3))\n",
    "    part3 = sign(scale(correlation(adv20, df['low'], 12)))\n",
    "    return part1 + part2 + part3\n",
    "\n",
    " @staticmethod\n",
    " def alpha_32(df):\n",
    "    part1 = scale((sum_(df['close'], 7) / 7) - df['close'])\n",
    "    part2 = 20 * scale(correlation(df['vwap'], delay(df['close'], 5), 230))\n",
    "    return part1 + part2\n",
    " \n",
    " @staticmethod\n",
    " def alpha_33(df):\n",
    "        # Alpha#33: rank((-1 * ((1 - (open / close))^1)))\n",
    "        factor = -1 * ((1 - (df['open'] / df['close'])) ** 1)\n",
    "        return rank(factor)\n",
    "\n",
    " @staticmethod\n",
    " def alpha_34(df):\n",
    "        # Alpha#34: rank(((1 - rank((stddev(returns, 2) / stddev(returns, 5)))) + (1 - rank(delta(close, 1)))))\n",
    "        std_2 = stddev(df['returns'], 2)\n",
    "        std_5 = stddev(df['returns'], 5)\n",
    "        delta_1 = delta(df['close'], 1)\n",
    "\n",
    "        rank_std_ratio = rank(std_2 / std_5)\n",
    "        rank_delta_close = rank(delta_1)\n",
    "\n",
    "        factor = (1 - rank_std_ratio) + (1 - rank_delta_close)\n",
    "        return rank(factor)\n",
    "\n",
    " @staticmethod\n",
    " def alpha_35(df):\n",
    "        # Alpha#35: ((Ts_Rank(volume, 32) * (1 - Ts_Rank(((close + high) - low), 16))) * (1 - Ts_Rank(returns, 32)))\n",
    "        ts_rank_volume = ts_rank(df['volume'], 32)\n",
    "        ts_rank_price_range = ts_rank((df['close'] + df['high'] - df['low']), 16)\n",
    "        ts_rank_returns = ts_rank(df['returns'], 32)\n",
    "\n",
    "        factor = ts_rank_volume * (1 - ts_rank_price_range) * (1 - ts_rank_returns)\n",
    "        return factor\n",
    "\n",
    " @staticmethod\n",
    " def alpha_36(df):\n",
    "    adv20 = df['volume'].rolling(window=20).mean()\n",
    "    part1 = 2.21 * rank(correlation(df['close'] - df['open'], delay(df['volume'], 1), 15))\n",
    "    part2 = 0.7 * rank(df['open'] - df['close'])\n",
    "    part3 = 0.73 * rank(ts_rank(delay(-1 * df['returns'], 6), 5))\n",
    "    part4 = rank(abs(correlation(df['vwap'], adv20, 6)))\n",
    "    part5 = 0.6 * rank((sum_(df['close'], 200) / 200 - df['open']) * (df['close'] - df['open']))\n",
    "    return part1 + part2 + part3 + part4 + part5\n",
    "\n",
    " @staticmethod\n",
    " def alpha_37(df):\n",
    "        # Alpha#37: rank(correlation(delay((open - close), 1), close, 200)) + rank(open - close)\n",
    "        delayed_diff = delay(df['open'] - df['close'], 1)\n",
    "        corr_val = correlation(delayed_diff, df['close'], 200)\n",
    "        return rank(corr_val) + rank(df['open'] - df['close'])\n",
    "\n",
    " @staticmethod\n",
    " def alpha_38(df):\n",
    "        # Alpha#38: (-1 * rank(ts_rank(close, 10))) * rank(close / open)\n",
    "        ts_rk = ts_rank(df['close'], 10)\n",
    "        return (-1 * rank(ts_rk)) * rank(df['close'] / df['open'])\n",
    "\n",
    "\n",
    " @staticmethod\n",
    " def alpha_39(df):\n",
    "    adv20 = df['volume'].rolling(window=20).mean()\n",
    "    part1 = rank(correlation(delay(df['open'] - df['close'], 1), df['close'], 200))\n",
    "    part2 = rank(df['open'] - df['close'])\n",
    "    part3 = (-1 * rank(ts_rank(df['close'], 10))) * rank(df['close'] / df['open'])\n",
    "    part4 = (-1 * rank(delta(df['close'], 7) * (1 - rank(decay_linear(df['volume'] / adv20, 9))))) * (1 + rank(sum_(df['returns'], 250)))\n",
    "    return part1 + part2 + part3 + part4\n",
    "\n",
    " @staticmethod\n",
    " def alpha_40(df):\n",
    "    return (-1 * rank(stddev(df['high'], 10))) * correlation(df['high'], df['volume'], 10)\n",
    "\n",
    " @staticmethod\n",
    " def alpha_41(df):\n",
    "    return ((df['high'] * df['low']) ** 0.5) - df['vwap']\n",
    "\n",
    " @staticmethod\n",
    " def alpha_42(df):\n",
    "    return rank(df['vwap'] - df['close']) / rank(df['vwap'] + df['close'])\n",
    "\n",
    " @staticmethod\n",
    " def alpha_43(df):\n",
    "    adv20 = df['volume'].rolling(window=20).mean()\n",
    "    \n",
    "    return ts_rank(df['volume'] / adv20, 20) * ts_rank(-1 * delta(df['close'], 7), 8) \n",
    "#####################################################################################################\n",
    "\n",
    "\n",
    "def get_latest_candles(symbol=\"BTCUSDT\", interval=\"1m\", limit=200):\n",
    "    url = f\"https://api.binance.com/api/v3/klines?symbol={symbol}&interval={interval}&limit={limit}\"\n",
    "    try:\n",
    "        data = requests.get(url).json()\n",
    "    except Exception as e:\n",
    "        print(\"❌ Error fetching data:\", e)\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\n",
    "        'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "        'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "        'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n",
    "    ])\n",
    "    df = df.astype({\n",
    "        'open': float, 'high': float, 'low': float,\n",
    "        'close': float, 'volume': float\n",
    "    })\n",
    "    df[\"returns\"] = df[\"close\"].pct_change()\n",
    "    typical_price = (df[\"high\"] + df[\"low\"] + df[\"close\"]) / 3\n",
    "    df[\"vwap\"] = (typical_price * df[\"volume\"]).cumsum() / df[\"volume\"].cumsum()\n",
    "    \n",
    "    return   df.dropna()\n",
    "\n",
    "def complute_all_alpha_zero(df):\n",
    "    for i in range(1,14):\n",
    "        func= getattr(Alpha_Zero, f'alpha_{i}')\n",
    "        df[f'alpha_factors_{i}'] = func(df)\n",
    "    return df.dropna()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    df = get_latest_candles(symbol=\"BTCUSDT\", interval=\"1m\", limit=200)\n",
    "\n",
    "    df = complute_all_alpha_zero(df)\n",
    "    print(df)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67342293",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7b30405",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import ta  # Make sure ta is installed: pip install ta\n",
    "\n",
    "        \n",
    "def complute_all_alpha_zero(df):\n",
    "    for i in range(1,18):\n",
    "        func= getattr(Alpha_Zero, f'alpha_{i}')\n",
    "        df[f'alpha_factors_{i}'] = func(df)\n",
    "    return df.dropna()\n",
    "\n",
    "FEATURE_COLUMNS = [\n",
    "    \"open\", \"high\", \"low\", \"close\", \"rsi\", \"stoch_rsi\",\n",
    "    \"macd_line\", \"macd_signal\", \"macd_diff\", \"sma_50\", \"sma_20\",\n",
    "    \"bb_bbm\", \"bb_bbh\", \"bb_bbl\", \"returns\", \"vwap\"\n",
    "] + [f\"alpha_factors_{i}\" for i in range(1, 18) if i != 28 and i != 19]  \n",
    "\n",
    "class genlenDataset(Dataset):\n",
    "    def __init__(self, df, qen_len=10):\n",
    "        self.qen_len = qen_len\n",
    "        self.scaler = MinMaxScaler()\n",
    "        print(\"Original df shape:\", df.shape)\n",
    "        print(\"Missing values per column:\\n\", df.isna().sum())\n",
    "        print(\"Number of inf values:\\n\", np.isinf(df.select_dtypes(include=[np.number])).sum())\n",
    "        \n",
    "        data = df[FEATURE_COLUMNS].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        scaled = self.scaler.fit_transform(data)\n",
    "        self.target = scaled[:, FEATURE_COLUMNS.index(\"close\")]\n",
    "        self.data = scaled\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.qen_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx: idx+self.qen_len]\n",
    "        y = self.target[idx+self.qen_len]\n",
    "        return torch.tensor(X,dtype= torch.float), torch.tensor(y,dtype= torch.float)     \n",
    "\n",
    "class LSTM_modul(nn.Module):\n",
    "    def __init__(self, input_size=14, hiddan_size=50):\n",
    "        super().__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hiddan_size, 6)\n",
    "        self.droup = nn.Dropout(0.2)\n",
    "        self.fc = nn.Linear(hiddan_size , 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.droup(out[:, -1 ,:])\n",
    "        return self.fc(out)   \n",
    "\n",
    "def train_model(dataloader, model, criterion, optimizer, epochs=1):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device) , y_batch.to(device)\n",
    "            optimizer.total_loss = 0\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch).squeeze(-1)\n",
    "            loss = criterion(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def predict_next(df, model, scaler, seq_len=10):\n",
    "    df = df[FEATURE_COLUMNS].copy()\n",
    "    df = df.replace([np.inf, - np.inf], np.nan).dropna()\n",
    "    \n",
    "    scaled = scaler.transform(df.values[-seq_len:])\n",
    "\n",
    "    input_tensor = torch.tensor(scaled, dtype=torch.float32).unsqueeze(0).to(next(model.parameters()).device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions =  model(input_tensor).cpu().numpy()\n",
    "    \n",
    "    \n",
    "    dummy = np.zeros((1, len(FEATURE_COLUMNS)))\n",
    "    close_index = FEATURE_COLUMNS.index(\"close\")\n",
    "        \n",
    "    dummy[0, 3] = predictions[0][0]\n",
    "    inv =scaler.inverse_transform(dummy)\n",
    "    return inv[0, close_index] \n",
    "\n",
    "\n",
    "def get_latest_candles(symbol=\"BTCUSDT\", interval=\"1m\", limit=200):\n",
    "    url = f\"https://api.binance.com/api/v3/klines?symbol={symbol}&interval={interval}&limit={limit}\"\n",
    "    try:\n",
    "        data = requests.get(url).json()\n",
    "    except Exception as e:\n",
    "        print(\"❌ Error fetching data:\", e)\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\n",
    "        'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "        'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "        'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n",
    "    ])\n",
    "    df = df.astype({\n",
    "        'open': float, 'high': float, 'low': float,\n",
    "        'close': float, 'volume': float\n",
    "    })\n",
    "\n",
    "    df['rsi'] = ta.momentum.RSIIndicator(close=df['close'], window=14).rsi()\n",
    "    df['stoch_rsi'] = ta.momentum.stochrsi(close=df['close'], window=14)\n",
    "    macd = ta.trend.MACD(close=df['close'])\n",
    "    df['macd_line'] = macd.macd()\n",
    "    df['macd_signal'] = macd.macd_signal()\n",
    "    df['macd_diff'] = macd.macd_diff()\n",
    "\n",
    "    df['sma_50'] = ta.trend.SMAIndicator(close=df['close'], window=50).sma_indicator()\n",
    "    df['sma_20'] = ta.trend.SMAIndicator(close=df['close'], window=20).sma_indicator()\n",
    "\n",
    "    bb_indicator  = ta.volatility.BollingerBands(close=df['close'])\n",
    "    df['bb_bbm'] = bb_indicator.bollinger_mavg()\n",
    "    df['bb_bbh'] = bb_indicator.bollinger_hband()\n",
    "    df['bb_bbl'] = bb_indicator.bollinger_lband()\n",
    "\n",
    "    df[\"returns\"] = df[\"close\"].pct_change()\n",
    "    typical_price = (df[\"high\"] + df[\"low\"] + df[\"close\"]) / 3\n",
    "    df[\"vwap\"] = (typical_price * df[\"volume\"]).cumsum() / df[\"volume\"].cumsum()\n",
    " \n",
    "    return df.dropna()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "modul = LSTM_modul().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(modul.parameters(), lr=0.01)\n",
    "\n",
    "latest_output = ''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = r\"C:\\Users\\User\\Documents\\clever-trade-bot-ai-main (8)\\clever-trade-bot-ai-main\\P_project_with_python\\Data_sources\\Alpha_factors\\data.csv\"\n",
    "    #df = get_latest_candles(symbol=\"BTCUSDT\", interval=\"1m\", limit=2000)\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    #df = alpha_factor.ta_factor_indcators(df)\n",
    "    #df = complute_all_alpha_zero(df)\n",
    "    print(df)\n",
    "    #df.to_csv('Data.csv')\n",
    "    df.dropna(inplace=True)  \n",
    "    print(df)\n",
    "\n",
    "    input_size = len(FEATURE_COLUMNS)\n",
    "    modul = LSTM_modul(input_size=input_size).to(device)\n",
    "    dataset = genlenDataset(df)\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    initial_loss = train_model(dataloader, modul, criterion, optimizer, epochs=3)\n",
    "    print(f\"🧪 Initial training loss: {initial_loss:.4f}\")\n",
    "\n",
    "    while True:\n",
    "        new_df = get_latest_candles(symbol=\"BTCUSDT\", interval=\"1m\", limit=200)\n",
    "        if new_df is not None:\n",
    "            new_df = complute_all_alpha_zero(new_df)\n",
    "            #new_df[\"returns\"] = new_df[\"close\"].pct_change()\n",
    "            #typical_price = (new_df[\"high\"] + new_df[\"low\"] + new_df[\"close\"]) / 3\n",
    "            #new_df[\"vwap\"] = (typical_price * new_df[\"volume\"]).cumsum() / new_df[\"volume\"].cumsum()\n",
    "            new_df.dropna(inplace=True)\n",
    "\n",
    "            dataset = genlenDataset(new_df)\n",
    "            dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "            loss = train_model(dataloader, modul, criterion, optimizer, epochs=1)\n",
    "            prediction = predict_next(new_df, modul, dataset.scaler, seq_len=10)\n",
    "\n",
    "            trend = \"🔼 Up\" if prediction > new_df[\"close\"].iloc[-1] else \"🔽 Down\"\n",
    "            print(f\"[{datetime.now().strftime('%H:%M:%S')}] 🔮 Close ≈ {prediction:.2f} USDT | Loss: {loss:.4f} | Trend: {trend}\")\n",
    "\n",
    "            torch.save(modul.state_dict(), \"model.pth\") \n",
    "        time.sleep(60)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf211a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.to_csv('Data.csv')\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'alpha_factor' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 180\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;66;03m#df = get_latest_candles(symbol=\"BTCUSDT\", interval=\"1m\", limit=2000)\u001b[39;00m\n\u001b[32m    178\u001b[39m df = pd.read_csv(path)\n\u001b[32m--> \u001b[39m\u001b[32m180\u001b[39m df = \u001b[43malpha_factor\u001b[49m.ta_factor_indcators(df)\n\u001b[32m    181\u001b[39m df = complute_all_alpha_zero(df)\n\u001b[32m    182\u001b[39m \u001b[38;5;28mprint\u001b[39m(df)\n",
      "\u001b[31mNameError\u001b[39m: name 'alpha_factor' is not defined"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "import requests\n",
    "import time\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import ta  # Make sure ta is installed: pip install ta\n",
    "\n",
    "        \n",
    "def complute_all_alpha_zero(df):\n",
    "    for i in range(1,18):\n",
    "        func= getattr(Alpha_Zero, f'alpha_{i}')\n",
    "        df[f'alpha_factors_{i}'] = func(df)\n",
    "    return df.dropna()\n",
    "\n",
    "FEATURE_COLUMNS = [\n",
    "    \"open\", \"high\", \"low\", \"close\", \"rsi\", \"stoch_rsi\",\n",
    "    \"macd_line\", \"macd_signal\", \"macd_diff\", \"sma_50\", \"sma_20\",\n",
    "    \"bb_bbm\", \"bb_bbh\", \"bb_bbl\", \"returns\", \"vwap\"\n",
    "] + [f\"alpha_factors_{i}\" for i in range(1, 18) if i != 28 and i != 19]  \n",
    "\n",
    "class genlenDataset(Dataset):\n",
    "    def __init__(self, df, qen_len=10):\n",
    "        self.qen_len = qen_len\n",
    "        self.scaler = MinMaxScaler()\n",
    "        print(\"Original df shape:\", df.shape)\n",
    "        print(\"Missing values per column:\\n\", df.isna().sum())\n",
    "        print(\"Number of inf values:\\n\", np.isinf(df.select_dtypes(include=[np.number])).sum())\n",
    "        \n",
    "        data = df[FEATURE_COLUMNS].replace([np.inf, -np.inf], np.nan).dropna()\n",
    "        scaled = self.scaler.fit_transform(data)\n",
    "        self.target = scaled[:, FEATURE_COLUMNS.index(\"close\")]\n",
    "        self.data = scaled\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) - self.qen_len\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        X = self.data[idx: idx+self.qen_len]\n",
    "        y = self.target[idx+self.qen_len]\n",
    "        return torch.tensor(X,dtype= torch.float), torch.tensor(y,dtype= torch.float)     \n",
    "\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        pe = pe.unsqueeze(0)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x + self.pe[:, :x.size(1), :]\n",
    "        return x \n",
    "\n",
    "class TimeSeriesTransformer(nn.Module):\n",
    "    def __init__(self, input_size, seq_len, d_model=128, nhead=8, num_layers=4, dim_feedforward=256, dropout=0.1):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.input_projection = nn.Linear(input_size, d_model)\n",
    "        \n",
    "        self.positional_encoding = PositionalEncoding(d_model=d_model, max_len=seq_len)\n",
    "        \n",
    "        encoding = nn.TransformerEncoderLayer(\n",
    "         d_model=d_model, nhead=nhead, dim_feedforward=dim_feedforward,\n",
    "         dropout=dropout, batch_first=True\n",
    "        )\n",
    "        self.transformer_encoder = nn.TransformerEncoder(encoding, num_layers=num_layers)\n",
    "\n",
    "        self.output_layer = nn.Linear(d_model, 1)\n",
    "\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, seq_len, input_size)\n",
    "        x = self.input_projection(x)                       # => (batch_size, seq_len, d_model)\n",
    "        x = self.positional_encoding(x)                    # add positional info\n",
    "        x = self.transformer_encoder(x)                    # Transformer encoding\n",
    "        x = x[:, -1, :]                                     # get the last time step\n",
    "        out = self.output_layer(x)                         # final prediction\n",
    "        return out\n",
    "\n",
    "\n",
    "def train_model(dataloader, model, criterion, optimizer, epochs=1):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for x_batch, y_batch in dataloader:\n",
    "            x_batch, y_batch = x_batch.to(device) , y_batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(x_batch).squeeze(-1)\n",
    "            loss = criterion(output, y_batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "def predict_next(df, model, scaler, seq_len=30):\n",
    "    df = df[FEATURE_COLUMNS].copy()\n",
    "    df = df.replace([np.inf, - np.inf], np.nan).dropna()\n",
    "    \n",
    "    scaled = scaler.transform(df.values[-seq_len:])\n",
    "\n",
    "    input_tensor = torch.tensor(scaled, dtype=torch.float32).unsqueeze(0).to(next(model.parameters()).device)\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        predictions =  model(input_tensor).cpu().numpy()\n",
    "    \n",
    "    \n",
    "    dummy = np.zeros((1, len(FEATURE_COLUMNS)))\n",
    "    close_index = FEATURE_COLUMNS.index(\"close\")\n",
    "        \n",
    "    dummy[0, close_index] = predictions[0][0]\n",
    "    inv =scaler.inverse_transform(dummy)\n",
    "    return inv[0, close_index] \n",
    "\n",
    "\n",
    "def get_latest_candles(symbol=\"BTCUSDT\", interval=\"1m\", limit=200):\n",
    "    url = f\"https://api.binance.com/api/v3/klines?symbol={symbol}&interval={interval}&limit={limit}\"\n",
    "    try:\n",
    "        data = requests.get(url).json()\n",
    "    except Exception as e:\n",
    "        print(\"❌ Error fetching data:\", e)\n",
    "        return None\n",
    "\n",
    "    df = pd.DataFrame(data, columns=[\n",
    "        'timestamp', 'open', 'high', 'low', 'close', 'volume',\n",
    "        'close_time', 'quote_asset_volume', 'number_of_trades',\n",
    "        'taker_buy_base_asset_volume', 'taker_buy_quote_asset_volume', 'ignore'\n",
    "    ])\n",
    "    df = df.astype({\n",
    "        'open': float, 'high': float, 'low': float,\n",
    "        'close': float, 'volume': float\n",
    "    })\n",
    "\n",
    "    df['rsi'] = ta.momentum.RSIIndicator(close=df['close'], window=14).rsi()\n",
    "    df['stoch_rsi'] = ta.momentum.stochrsi(close=df['close'], window=14)\n",
    "    macd = ta.trend.MACD(close=df['close'])\n",
    "    df['macd_line'] = macd.macd()\n",
    "    df['macd_signal'] = macd.macd_signal()\n",
    "    df['macd_diff'] = macd.macd_diff()\n",
    "\n",
    "    df['sma_50'] = ta.trend.SMAIndicator(close=df['close'], window=50).sma_indicator()\n",
    "    df['sma_20'] = ta.trend.SMAIndicator(close=df['close'], window=20).sma_indicator()\n",
    "\n",
    "    bb_indicator  = ta.volatility.BollingerBands(close=df['close'])\n",
    "    df['bb_bbm'] = bb_indicator.bollinger_mavg()\n",
    "    df['bb_bbh'] = bb_indicator.bollinger_hband()\n",
    "    df['bb_bbl'] = bb_indicator.bollinger_lband()\n",
    "\n",
    "    df[\"returns\"] = df[\"close\"].pct_change()\n",
    "    typical_price = (df[\"high\"] + df[\"low\"] + df[\"close\"]) / 3\n",
    "    df[\"vwap\"] = (typical_price * df[\"volume\"]).cumsum() / df[\"volume\"].cumsum()\n",
    " \n",
    "    return df.dropna()\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "modul = TimeSeriesTransformer(input_size=len(FEATURE_COLUMNS), seq_len=30).to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(modul.parameters(), lr=0.01)\n",
    "\n",
    "latest_output = ''\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    path = r\"C:\\Users\\User\\Documents\\clever-trade-bot-ai-main (8)\\clever-trade-bot-ai-main\\P_project_with_python\\Data_sources\\Alpha_factors\\2.csv\"\n",
    "    #df = get_latest_candles(symbol=\"BTCUSDT\", interval=\"1m\", limit=2000)\n",
    "    \n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    df = alpha_factor.ta_factor_indcators(df)\n",
    "    df = complute_all_alpha_zero(df)\n",
    "    print(df)\n",
    "    df.to_csv('Data_00.csv')\n",
    "    df.dropna(inplace=True)  \n",
    "    print(df)\n",
    "\n",
    "    input_size = len(FEATURE_COLUMNS)\n",
    "    modul = TimeSeriesTransformer(input_size=input_size, seq_len=30).to(device)\n",
    "    dataset = genlenDataset(df, qen_len=30)\n",
    "    dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "    initial_loss = train_model(dataloader, modul, criterion, optimizer, epochs=3)\n",
    "    print(f\"🧪 Initial training loss: {initial_loss:.4f}\")\n",
    "\n",
    "    while True:\n",
    "        new_df = get_latest_candles(symbol=\"BTCUSDT\", interval=\"1m\", limit=200)\n",
    "        if new_df is not None:\n",
    "            new_df = complute_all_alpha_zero(new_df)\n",
    "            #new_df[\"returns\"] = new_df[\"close\"].pct_change()\n",
    "            #typical_price = (new_df[\"high\"] + new_df[\"low\"] + new_df[\"close\"]) / 3\n",
    "            #new_df[\"vwap\"] = (typical_price * new_df[\"volume\"]).cumsum() / new_df[\"volume\"].cumsum()\n",
    "            new_df.dropna(inplace=True)\n",
    "\n",
    "            dataset = genlenDataset(new_df)\n",
    "            dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
    "            loss = train_model(dataloader, modul, criterion, optimizer, epochs=1)\n",
    "            prediction = predict_next(new_df, modul, dataset.scaler, seq_len=10)\n",
    "\n",
    "            trend = \"🔼 Up\" if prediction > new_df[\"close\"].iloc[-1] else \"🔽 Down\"\n",
    "            print(f\"[{datetime.now().strftime('%H:%M:%S')}] 🔮 Close ≈ {prediction:.2f} USDT | Loss: {loss:.4f} | Trend: {trend}\")\n",
    "\n",
    "            torch.save(modul.state_dict(), \"model.pth\") \n",
    "        time.sleep(60)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca45933b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ccxt\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "\n",
    "exchange = ccxt.binance()\n",
    "\n",
    "all_data = []\n",
    "limit = 1000\n",
    "since = exchange.parse8601('2025-06-09T18:58:00')\n",
    "symbol = 'BTC/USDT'\n",
    "\n",
    "path = r'C:\\Users\\User\\Documents\\clever-trade-bot-ai-main (8)\\message_types.csv'\n",
    "\n",
    "file_exists = os.path.exists(path)\n",
    "\n",
    "while since < exchange.milliseconds():\n",
    "    ohlcv = exchange.fetch_ohlcv(symbol, timeframe='1m', since=since, limit=limit)\n",
    "    if not ohlcv:\n",
    "        break\n",
    "\n",
    "    df = pd.DataFrame(ohlcv, columns=['timestamp', 'open', 'high', 'low', 'close', 'volume'])\n",
    "    df['timestamp'] = pd.to_datetime(df['timestamp'], unit='ms')\n",
    "    \n",
    "    df.to_csv(path, mode='a', header=not file_exists, index=False)\n",
    "    file_exists = True  #   \n",
    "\n",
    "    since = ohlcv[-1][0] + 60_000  #  \n",
    "    time.sleep(0.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8c56b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91f5bcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
